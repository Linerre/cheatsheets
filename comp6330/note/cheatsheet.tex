\documentclass[8pt,a4paper,landscape]{extarticle}
\input{preamble}

\begin{document}
% Suppress page number for all pages
\pagestyle{empty}

% Notes begin
\begin{multicols*}{3}
% \input{subs/ch14_vm_api}
% \input{subs/ch15_vm_addrtrans}
% \input{subs/ch16_vm_seg}
% \input{subs/ch20_ptarithm}

% \pagebreak
% \input{subs/ch18_intro_paging}
% \columnbreak
% \input{subs/ch19_tlb}
% \input{subs/ch20_hybrid}
% \input{subs/ch20_2levelpt}
% \input{subs/ch20_multi_level_pt}
% \input{subs/ch21_swap}
% \columnbreak
% \input{subs/ch22_swap_policy}
% \input{subs/ch28_locks}
% \input{subs/ch29_locked_dt}
% \input{subs/ch30_cv}
% \input{subs/ch31_sem}
% \input{subs/ch32_conbug}
\section*{I/O Devices (allows information to persist; RAM is volatile)}
\begin{minipage}{.5\linewidth}
\includegraphics[width=\linewidth]{imgs/prototypical_sys_arch}
\end{minipage}
\begin{minipage}{.5\linewidth}
\includegraphics[width=\linewidth]{imgs/modern_sys_arch}
\end{minipage}
\begin{minipage}{.5\linewidth}
  \flushleft
  \begin{itemize}
  \item The faster a bus is, the shorter it must be $\to$ high-performance memory bus doesn't have much room for many devices
  \item components that demand high performance (such as graphics card) placed nearer CPU
  \item lower performance components are further away
  \end{itemize}
\end{minipage}
\begin{minipage}{.5\linewidth}
  \flushleft
  \begin{itemize}
  \item modern sys use specialized chipsets and faster point-to-point inter-conn to $\uparrow$ performance; USB (Universal Serial Bus) is used for low performance devices
  \item OS handles device management (and access); OS exposes uniform interface to applications
  \item IO is interrupt driven
  \end{itemize}
\end{minipage}
\begin{minipage}{.65\linewidth}
\includegraphics[width=\linewidth]{imgs/otherio}
\end{minipage}
\begin{minipage}{.35\linewidth}
  \flushleft
  \begin{itemize}
  \item Northbridge, aka memory controller hub
  \item Southbrigge, aka I/O Controller Hub (Intel) or Fusion Controller Hub (AMD)
  \item southbridge connected to CPU through northbridge which has a direct connection
  \end{itemize}
\end{minipage}
\section*{Canonical Devices (an abstraction with 2 components)}
\includegraphics[width=\linewidth]{imgs/canonical_dev}
\begin{itemize}
\item \textbf{status} register to be read to see the current status of the device
\item \textbf{command} register to tell the device to perform a certain task
\item \textbf{data} register pass data to the device, or get data from
the device
\end{itemize}
\begin{enumerate}
\item \textbf{hardware interface} presents to the rest of the system. Hardware must present some kind of interface that allows the system
software to control its operation. Thus, all devices have some specified
interface and protocol for typical interaction
\item \textbf{internal structure}, implementation specific and responsible for implementing the abstraction the device presents to the system
  \begin{itemize}
  \item Very simple devices will have one/a few hardware chips
  \item more complex devices will include a simple CPU, some general purpose
memory, and other device-specific chips, e.g modern RAID controllers might consist of hundreds of thousands of lines of firmware (i.e. software within a hardware device)  to impl. its functionality
  \end{itemize}
\end{enumerate}
\section*{Canonical Protocol (4 steps, simple yet inefficient)}
\begin{enumerate}
\item OS waits until the device ready to receive a command by repeatedly reading the status register (\textbf{polling} the device)
\item OS sends some data down to data register
  \begin{itemize}
  \item multiple writes to transfer a disk block (say 4KB) to the device
  \item if main CPU involved (as in this case) $\to$ \textbf{programmed I/O} (PIO)
  \end{itemize}
\item OS writes a command to command register $\to$ implicitly tell the device that data is present and device should begin working on the command
\item OS waits for the device to finish by again polling it in a loop, waiting to see if it is finished (return code for success/error)
\end{enumerate}
\begin{lstlisting}[language=c]
While (STATUS == BUSY)
    ; // wait until device is not busy
Write data to DATA register // set up everything before any cmd exec
Write command to COMMAND register
    (starts the device and executes the command)
While (STATUS == BUSY)
    ; // wait until device is done with your request
\end{lstlisting}
\section*{Lowering CPU Overhead with Interrupts}
\begin{minipage}{.5\linewidth}
\includegraphics[width=\linewidth]{imgs/iopolling}
\end{minipage}
\begin{minipage}{.5\linewidth}
\includegraphics[width=\linewidth]{imgs/iointerrupt}
\end{minipage}
\begin{minipage}{.5\linewidth}
  \flushleft
  \begin{enumerate}
  \item $P_1$ runs on CPU for some time (repeated \texttt{1} on CPU line)
  \item then issues I/O request to disk to read some data
  \item OS spins, polling status of device repeatedly until I/O completes
  \item disk serves req; $P_1$ can run again
  \end{enumerate}
\end{minipage}
\begin{minipage}{.5\linewidth}
  \flushleft
  \begin{enumerate}
  \item OS runs $P_2$ on CPU while disk services $P_1$'s request
  \item When disk request is done, an interrupt occurs
  \item OS wakes up $P_1$, runs it again
  \item \mb{both} CPU and disk get properly utilized during the middle
  \end{enumerate}
\end{minipage}
\begin{tcolorbox}[left=0mm, top=1mm, right=0mm, rightlower=0mm, bottom=1mm,
  title= Interrupts \mr{NOT always} better than polling,
  halign title=center]
  Although interrupts allow for overlap of computation and I/O, they only
  really \mb{make sense for slow devices}. Otherwise, the cost of interrupt handling and context switching may outweigh the benefits interrupts provide.  If a device performs its tasks \emph{very quickly}: the 1st poll usually finds the device done with task. Using an interrupt in this case will actually \emph{slow down} the system: switching to another process, handling the interrupt, and switching back to the issuing process is expensive.

  There are also cases where a flood of interrupts may overload a system and lead it to \textbf{livelock}; in such cases, polling provides more control to the OS in its scheduling and thus is again useful.
\end{tcolorbox}
\begin{itemize}
\item if a device is fast, best to poll; if it's slow, best to interrupt (overlap)
\item If device speed is unknown (sometimes fast, sometimes slow), best to \textbf{hybrid}: polls for a short while and if device not yet finished, interrupts
\item This \textbf{two-phased} approach may achieve the best of both worlds
\end{itemize}
In networks, when a huge stream of incoming packets each generate an interrupt, OS may \textbf{livelock}: find itself only processing interrupts and never running a user-level process and actually servicing requests
\begin{itemize}
\item a web server with a load burst $\because$ it became top-ranked on hacker news
\item In this case, it's better to occasionally poll to better control what's happening in system and allow server to fulfill some requests before going back to the device to check for more packet arrivals
\end{itemize}
Another interrupt-based optimization is \textbf{coalescing}:
\begin{itemize}
\item a device first waits for a bit before delivering its interrupt to CPU
\item While waiting, other requests may soon complete $\to$ multiple interrupts can be coalesced into a single delivery $\to$ lowering overhead
\item yet waiting too long $\to$ request latency $\uparrow$: common trade-off in systems
\end{itemize}
\section*{More Efficient Data Movement With DMA}
\end{multicols*}
\end{document}
