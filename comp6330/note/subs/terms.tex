\begin{description}
\item[address space] (of a process) contains all of the memory state of the
running program: the \textbf{code} of the program (the instructions); The running program uses a \textbf{stack} to keep track of where it is in function call chain as well as to allocate local variables and pass parameters and return values to and from routines; the \textbf{heap} is used for dynamically-allocated, user-managed memory, etc.  It is the running program’s view of memory in the system

\item[Access Control List (ACL)]  Access control lists are a more general and powerful way to represent exactly who can access a given resource. In a file system, this enables a user to create a very specific list of who can and cannot read a set of files, in contrast to the somewhat limited owner/group/everyone model of permissions bits.

\item[atomicity violation] The desired serializability among multiple memory accesses is violated (i.e. a code region is intended to be atomic, but the atomicity is not enforced during execution)

\item[order violation] The desired order between two (groups of) memory accesses is flipped (i.e., A should always be executed before B, but the order is not enforced during execution)

\item[condition variable] an explicit queue that threads can put themselves on when some state of execution (i.e., some \textbf{condition}) is \emph{not} as desired (by \textbf{waiting} on the condition); some other thread, when it changes said state, can then wake one (or more) of those waiting threads and thus allow them to continue (by signaling on the condition). The idea goes back to Dijkstra's use of ``private semaphores''; a similar idea was later named a ``condition variable'' by Hoare in his work on monitors.

\item[deadlock avoidance] Avoidance requires some global knowledge of which locks various threads might grab during their execution, and subsequently \textbf{schedules} said threads in a way as to guarantee no deadlock can occur.

\item[DMI]  Intel’s proprietary DMI (Direct Media Interface), for connecting I/O Chip

\item[eSATA] external SATA represent an evolution of storage interfaces over the past decades, with each step forward increasing performance to keep pace with modern storage devices

\item[File] A file is an array of bytes which can be created, read, written, and deleted. It has a low-level name (i.e., a number) that refers to it uniquely. The low-level name is often called an \textbf{inode number} (\textbf{i-number}).  A file, as presented to the user via a file name, is essentially a “pointer” to the underlying inode that structure in the disk that contains the actual data. Different ways to refer to a file:
\begin{enumerate*}[label={\alph*.},font={\color{red!50!black}\bfseries}]
\item file name (human readable)
\item inode number (persistent ID)
\item file descriptor (process view)
\end{enumerate*}

\item[File Descriptor] To access a file, a process must use a system call (usually, \texttt{open()}) to request permission from the operating system. If permission is granted, the OS returns a \textbf{file descriptor} (an \texttt{int}, private per process and is used in UNIX systems), which can then be used for read or write access, as permissions and intent allow.  Thus, a file descriptor is a capability, i.e., an opaque handle that gives you the power to perform certain operations.  When you first open another file, it will almost certainly be file descriptor \textbf{3}, because In Linux, by default a process already has \textbf{3} file descriptors:
\begin{enumerate*}[label={\alph*.},font={\color{red!50!black}\bfseries}]
\item standard input (0)
\item standard output (1)
\item standard error (2)
\end{enumerate*}


\item[File Type]  In some systems (Windows), a file's name carry a structure: a two-part name, separated by a \texttt{.}: \texttt{filename.ext}. This is mostly a \textbf{convention}, so no enforcement on the data contained in the file. Other systems adopt an untyped view: no convention to relate to specific content of the file.

\item[Directory] a collection of tuples, each of which contains a human-readable name and low-level name to which it maps. Each entry refers either to another directory or to a file. Each directory also has a low-level name (i-number) itself. A directory always has two special entries: the \textbf{\texttt{.}} entry, which refers to itself, and the \textbf{\texttt{..}} entry, which refers to its parent.

\item[Directory Tree/Hierarchy] organizes all files and directories into a large tree, starting at the \textbf{root} (often represented as \texttt{/}).

\item[SATA] Serial ATA (AT Attachment)

\item[Hill's law] One early source is Mark Hill's dissertation, which studied how to design caches for CPUs. Hill found that simple direct-mapped caches worked better than fancy set-associative designs (one reason is that in caching, simpler designs enable faster lookups). As Hill succinctly summarized
  his work: ``Big and dumb is better.'' And thus we call this similar advice Hill's Law.

\item[Lauer's law] As Hugh Lauer said, when discussing the construction of the Pilot operating system: ``If the same people had twice as much time, they could produce as good of a system in half the code.''

\item[limited direct execution] let the program run directly on the hardware; however, at certain key points in time (such as when a process issues a system call, or a timer interrupt occurs), arrange so that the OS gets involved and makes sure the ``right'' thing happens.   Thus, the OS, with a little hardware support, tries best to get out of the way of the running program, to deliver an \emph{efficient} virtualization.

\item[lock] Generally, Programmers annotate source code with locks, putting them around critical sections, and thus ensure that any such critical section executes as if it were a single \textbf{atomic} instruction.

\item[LRU] least recently used: take advantage of locality in the memory-reference stream, assuming it is likely that an entry that has not recently been used is a good
candidate for eviction.

\item[mesa semantics] Signaling a thread only wakes them up; it is thus a hint that the state of the world has changed (in this case, that a value has been placed in the buffer), but there is no guarantee that when the woken thread runs, the state will still be as desired. This interpretation of what a signal means is often referred to as Mesa semantics (1st implemented in Mesa programming language). In contrast, \textbf{Hoare semantics} requires the woken thread be run immediately.  Most (if not all) systems use the Mesa semantics.

\item[memory virtualization] OS maps user program address space to physical memory address.

\item[memory management unit] the part of the processor that helps with address translation (base and bounds registers kept on the chip).

\item[most-recently-used (MRU)] MostFrequently-Used (MFU) and Most-Recently-Used (MRU). In most cases (not all!), these policies do not work well, as they ignore the locality most programs exhibit instead of embracing it.

\item[mutex] The name that the POSIX library uses for a lock, as it is used to provide mutual exclusion between threads, i.e., if one thread is in the critical section, it excludes the others from entering until it has completed the section.

\item[Open File Table] Each file descriptor is a private, per-process entity. Each process maintains an array of file descriptors, each of which refers to an entry in the system-wide \textbf{open file table}. The entry therein tracks which file this access refers to, the \textbf{current offset} of the file (i.e., which part of the file the next read or write will access), and other relevant details such as whether the file is readable or writable

\item[paging] Chop memory into \emph{fixed-sized} pieces, each called a \textbf{page}

\item[page frame] physical memory viewed as an array of fixed-sized slots called page frames; each of these frames can contain a single virtual-memory page.

\item[page table] s a per-process data structure maintained by OS.  Its major role is to store address translations for each of the virtual pages of the address space, thus letting us know where in physical memory each page resides.

\item[page fault] the act of accessing a page that is not in physical memory.  Upon a page fault, the OS is invoked to service the page fault.  Virtually all systems handle page faults in software.

\item[segmentation] Chop memory into \textsw{variable-sized} chunks and allocate them based on needs (e.g in base/bound or segmentation approaches)

\item[segmentation fault] a violation or error arising from a memory access on a segmented machine to an illegal address.

\item[sparse address space] large address spaces with large amounts of unused address space

\item[time-space-trade-offs] Usually, if you wish to make access to a particular data structure faster, you will have to pay a space-usage penalty for the structure.

\item[throttling] an approach where programmer decides upon a threshold for ``too many'', and then use a semaphore to limit the number of threads concurrently executing the piece of code in question.  This is also a form of \textbf{admission control}. Imagine that you create hundreds of threads to work on some problem in parallel. However, in a certain part of the code, each thread acquires a large amount of memory to perform part of the computation; let’s call this part of the code the \emph{memory-intensive region}. If \emph{all} of the threads enter the memory-intensive region at the same time, the sum of all the memory allocation requests will exceed the amount of physical memory on the machine. As a result, the machine will start thrashing (i.e., swapping pages to and from the disk), and the entire computation will slow to a crawl.  A simple semaphore can solve this problem. By initializing the value of the semaphore to the maximum number of threads you wish to enter the memory-intensive region at once, and then putting a \texttt{sem\_wait()} and \texttt{sem\_post()} around the region, a semaphore can naturally throttle the number of threads that are ever concurrently in the dangerous region of the code.

\item[Time of Check To Time of Use (TOCTTOU)] McPhee notes that ``... if there exists a time interval between a validity-check and the operation connected with that validity-check, [and,] through multitasking, the validity-check variables can deliberately be changed during this time interval, resulting in an invalid operation being performed by the control program'', thus this problem.  There are not any simple and great solutions to the TOCTTOU problem. One approach is to reduce the number of services that need root privileges to run, which helps. The \texttt{O\_NOFOLLOW} flag makes it so that \texttt{open()} will fail if the target is a symbolic link, thus avoiding attacks that require said links.

\item[translation-lookaside buffer (TLB)] part of the chip’s memory-management unit (MMU), and is simply a hardware cache of popular virtual-to-physical address translations; thus, a better name would be an address-translation cache.


\item[unwritten contract of disk drives] Specifically, one can usually assume that accessing two blocks near one-another within the drive’s address space will be faster than accessing two blocks that are far apart. One can also usually assume that accessing blocks in a contiguous chunk (i.e., a sequential read or write) is the fastest access mode, and usually much faster than any more random access pattern.

\item[virtual address] All that in user program address space



\end{description}
